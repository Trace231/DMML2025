#!/usr/bin/env python3
"""è¯Šæ–­ DataLoader æ€§èƒ½ç“¶é¢ˆçš„è„šæœ¬ã€‚

ä½¿ç”¨æ–¹æ³•:
    python scripts/diagnose_dataloader_perf.py --config configs/voc_benchmark.yaml
"""

import argparse
import time
import torch
from torch.utils.data import DataLoader
from pathlib import Path
import yaml
import sys

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.segmentation_benchmark.data import create_dataloaders


def benchmark_dataloader(loader: DataLoader, num_batches: int = 50, warmup: int = 5) -> dict:
    """æµ‹è¯• DataLoader çš„æ€§èƒ½ã€‚
    
    Returns:
        dict: åŒ…å«å„ç§æ€§èƒ½æŒ‡æ ‡çš„å­—å…¸
    """
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    # Warmup
    print(f"Warming up with {warmup} batches...")
    for i, batch in enumerate(loader):
        if i >= warmup - 1:
            break
        # æ¨¡æ‹Ÿ GPU ä¼ è¾“
        if torch.cuda.is_available():
            batch["image"].to(device, non_blocking=True)
            batch["mask"].to(device, non_blocking=True)
    
    # å®é™…æµ‹è¯•
    print(f"Benchmarking {num_batches} batches...")
    times = []
    data_times = []
    gpu_times = []
    
    start_total = time.time()
    loader_iter = iter(loader)
    
    for i in range(num_batches):
        # æµ‹é‡æ•°æ®åŠ è½½æ—¶é—´
        data_start = time.time()
        try:
            batch = next(loader_iter)
        except StopIteration:
            loader_iter = iter(loader)
            batch = next(loader_iter)
        data_time = time.time() - data_start
        data_times.append(data_time)
        
        # æµ‹é‡ GPU ä¼ è¾“æ—¶é—´
        if torch.cuda.is_available():
            gpu_start = time.time()
            batch["image"].to(device, non_blocking=True)
            batch["mask"].to(device, non_blocking=True)
            torch.cuda.synchronize()  # ç¡®ä¿ä¼ è¾“å®Œæˆ
            gpu_time = time.time() - gpu_start
            gpu_times.append(gpu_time)
        else:
            gpu_times.append(0.0)
        
        total_time = data_time + (gpu_times[-1] if torch.cuda.is_available() else 0)
        times.append(total_time)
        
        if (i + 1) % 10 == 0:
            print(f"  Processed {i+1}/{num_batches} batches...")
    
    total_time = time.time() - start_total
    
    # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    stats = {
        "num_batches": num_batches,
        "total_time": total_time,
        "avg_time_per_batch": sum(times) / len(times),
        "avg_data_time": sum(data_times) / len(data_times),
        "avg_gpu_time": sum(gpu_times) / len(gpu_times) if gpu_times else 0,
        "min_data_time": min(data_times),
        "max_data_time": max(data_times),
        "median_data_time": sorted(data_times)[len(data_times) // 2],
        "throughput_batches_per_sec": num_batches / total_time,
        "data_loading_ratio": sum(data_times) / total_time,
        "gpu_transfer_ratio": sum(gpu_times) / total_time if gpu_times else 0,
    }
    
    return stats


def diagnose_bottleneck(stats: dict, num_workers: int, batch_size: int) -> list:
    """è¯Šæ–­æ€§èƒ½ç“¶é¢ˆå¹¶ç»™å‡ºå»ºè®®ã€‚"""
    issues = []
    suggestions = []
    
    # æ£€æŸ¥æ•°æ®åŠ è½½æ—¶é—´
    if stats["avg_data_time"] > 0.1:  # å¦‚æœæ¯ä¸ª batch åŠ è½½æ—¶é—´è¶…è¿‡ 100ms
        issues.append("æ•°æ®åŠ è½½æ—¶é—´è¾ƒé•¿")
        if stats["data_loading_ratio"] > 0.5:
            issues.append("æ•°æ®åŠ è½½æ˜¯ä¸»è¦ç“¶é¢ˆ (>50% æ—¶é—´)")
    
    # æ£€æŸ¥ worker æ•°é‡
    if num_workers > 16:
        issues.append(f"Worker æ•°é‡ ({num_workers}) å¯èƒ½è¿‡å¤š")
        suggestions.append(f"å»ºè®®å‡å°‘åˆ° 8-16 ä¸ª workersï¼ˆç»éªŒæ³•åˆ™ï¼š2-4 * CPU æ ¸å¿ƒæ•°ï¼‰")
    
    if num_workers == 0:
        issues.append("ä½¿ç”¨å•çº¿ç¨‹æ•°æ®åŠ è½½")
        suggestions.append("å»ºè®®è®¾ç½® num_workers=4-8 ä»¥åˆ©ç”¨å¤šæ ¸ CPU")
    
    # æ£€æŸ¥ GPU ä¼ è¾“
    if stats["gpu_transfer_ratio"] > 0.3:
        issues.append("GPU ä¼ è¾“å ç”¨è¾ƒå¤šæ—¶é—´")
        suggestions.append("ç¡®ä¿ä½¿ç”¨ pin_memory=True å’Œ non_blocking=True")
    
    # æ£€æŸ¥ååé‡
    if stats["throughput_batches_per_sec"] < 1.0:
        issues.append("ååé‡è¾ƒä½ (<1 batch/s)")
        suggestions.append("è€ƒè™‘å¢åŠ  batch_size æˆ–ä¼˜åŒ–æ•°æ®é¢„å¤„ç†")
    
    # æ£€æŸ¥æ•°æ®åŠ è½½æ—¶é—´æ³¢åŠ¨
    if stats["max_data_time"] / stats["min_data_time"] > 3.0:
        issues.append("æ•°æ®åŠ è½½æ—¶é—´æ³¢åŠ¨è¾ƒå¤§")
        suggestions.append("å¯èƒ½æ˜¯ I/O ç“¶é¢ˆæˆ–æ•°æ®é¢„å¤„ç†å¤æ‚åº¦ä¸ä¸€è‡´")
    
    return issues, suggestions


def main():
    parser = argparse.ArgumentParser(description="è¯Šæ–­ DataLoader æ€§èƒ½")
    parser.add_argument("--config", type=str, required=True, help="é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--num-batches", type=int, default=50, help="æµ‹è¯•çš„ batch æ•°é‡")
    parser.add_argument("--warmup", type=int, default=5, help="é¢„çƒ­ batch æ•°é‡")
    parser.add_argument("--test-workers", type=int, nargs="+", default=None,
                       help="è¦æµ‹è¯•çš„ worker æ•°é‡åˆ—è¡¨ï¼ˆä¾‹å¦‚ï¼š0 4 8 16ï¼‰")
    args = parser.parse_args()
    
    # åŠ è½½é…ç½®
    with open(args.config, "r") as f:
        config = yaml.safe_load(f)
    
    dataset_cfg = config.get("dataset", {})
    default_num_workers = dataset_cfg.get("num_workers", 0)
    
    # ç¡®å®šè¦æµ‹è¯•çš„ worker æ•°é‡
    if args.test_workers:
        test_workers = args.test_workers
    else:
        # é»˜è®¤æµ‹è¯•å‡ ä¸ªå¸¸è§çš„å€¼
        test_workers = [0, 4, 8, 16, default_num_workers]
        test_workers = sorted(set(test_workers))  # å»é‡å¹¶æ’åº
    
    print("=" * 80)
    print("DataLoader æ€§èƒ½è¯Šæ–­å·¥å…·")
    print("=" * 80)
    print(f"é…ç½®æ–‡ä»¶: {args.config}")
    print(f"é»˜è®¤ num_workers: {default_num_workers}")
    print(f"æµ‹è¯•çš„ worker æ•°é‡: {test_workers}")
    print(f"æµ‹è¯• batch æ•°é‡: {args.num_batches}")
    print("=" * 80)
    print()
    
    results = {}
    
    for num_workers in test_workers:
        print(f"\n{'='*80}")
        print(f"æµ‹è¯• num_workers = {num_workers}")
        print(f"{'='*80}")
        
        # ä¸´æ—¶ä¿®æ”¹é…ç½®
        test_cfg = dataset_cfg.copy()
        test_cfg["num_workers"] = num_workers
        
        # åˆ›å»º DataLoader
        try:
            dataloaders = create_dataloaders(test_cfg)
            train_loader = dataloaders["train_loader"]
            
            # æ£€æŸ¥ DataLoader é…ç½®
            print(f"\nDataLoader é…ç½®:")
            print(f"  num_workers: {train_loader.num_workers}")
            print(f"  batch_size: {train_loader.batch_size}")
            print(f"  pin_memory: {getattr(train_loader, 'pin_memory', False)}")
            print(f"  prefetch_factor: {getattr(train_loader, 'prefetch_factor', 2)}")
            print(f"  persistent_workers: {getattr(train_loader, 'persistent_workers', False)}")
            
            # è¿è¡ŒåŸºå‡†æµ‹è¯•
            stats = benchmark_dataloader(train_loader, args.num_batches, args.warmup)
            results[num_workers] = stats
            
            # æ‰“å°ç»“æœ
            print(f"\næ€§èƒ½ç»Ÿè®¡:")
            print(f"  æ€»æ—¶é—´: {stats['total_time']:.2f}s")
            print(f"  å¹³å‡æ¯ batch æ—¶é—´: {stats['avg_time_per_batch']:.4f}s")
            print(f"  å¹³å‡æ•°æ®åŠ è½½æ—¶é—´: {stats['avg_data_time']:.4f}s")
            if stats['avg_gpu_time'] > 0:
                print(f"  å¹³å‡ GPU ä¼ è¾“æ—¶é—´: {stats['avg_gpu_time']:.4f}s")
            print(f"  ååé‡: {stats['throughput_batches_per_sec']:.2f} batches/s")
            print(f"  æ•°æ®åŠ è½½å æ¯”: {stats['data_loading_ratio']*100:.1f}%")
            if stats['gpu_transfer_ratio'] > 0:
                print(f"  GPU ä¼ è¾“å æ¯”: {stats['gpu_transfer_ratio']*100:.1f}%")
            print(f"  æ•°æ®åŠ è½½æ—¶é—´èŒƒå›´: {stats['min_data_time']:.4f}s - {stats['max_data_time']:.4f}s")
            
            # è¯Šæ–­
            issues, suggestions = diagnose_bottleneck(
                stats, num_workers, train_loader.batch_size
            )
            
            if issues:
                print(f"\nâš ï¸  å‘ç°çš„é—®é¢˜:")
                for issue in issues:
                    print(f"  - {issue}")
            
            if suggestions:
                print(f"\nğŸ’¡ å»ºè®®:")
                for suggestion in suggestions:
                    print(f"  - {suggestion}")
        
        except Exception as e:
            print(f"âŒ é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
    
    # æ¯”è¾ƒç»“æœ
    if len(results) > 1:
        print(f"\n{'='*80}")
        print("æ€§èƒ½æ¯”è¾ƒ")
        print(f"{'='*80}")
        print(f"{'num_workers':<12} {'ååé‡ (batches/s)':<20} {'å¹³å‡åŠ è½½æ—¶é—´ (s)':<20}")
        print("-" * 80)
        for num_workers in sorted(results.keys()):
            stats = results[num_workers]
            print(f"{num_workers:<12} {stats['throughput_batches_per_sec']:<20.2f} {stats['avg_data_time']:<20.4f}")
        
        # æ‰¾å‡ºæœ€ä½³é…ç½®
        best_workers = max(results.keys(), key=lambda w: results[w]['throughput_batches_per_sec'])
        best_throughput = results[best_workers]['throughput_batches_per_sec']
        print(f"\nâœ… æœ€ä½³é…ç½®: num_workers={best_workers} (ååé‡: {best_throughput:.2f} batches/s)")
        
        if best_workers != default_num_workers:
            print(f"âš ï¸  å½“å‰é…ç½®ä½¿ç”¨ num_workers={default_num_workers}ï¼Œå»ºè®®æ”¹ä¸º {best_workers}")


if __name__ == "__main__":
    main()

